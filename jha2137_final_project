{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"jha2137_final_project","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USII95Iu27MB","executionInfo":{"status":"ok","timestamp":1619443186856,"user_tz":300,"elapsed":21928,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}},"outputId":"590f473e-5653-4893-823b-1379c86df956"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ASxIkyQvhE3H"},"source":["!pip install tensorflow==2.3.1\n","!apt-get install openslide-tools\n","!pip install openslide-python"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLtERc8acCe7","executionInfo":{"status":"ok","timestamp":1619443266937,"user_tz":300,"elapsed":101993,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from openslide import open_slide, __library_version__ as openslide_version\n","import os\n","from PIL import Image\n","from skimage.color import rgb2gray\n","import time\n","import gc"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUL1L5jUcJeW","executionInfo":{"status":"ok","timestamp":1619443270222,"user_tz":300,"elapsed":105273,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n","from keras.layers.merge import concatenate\n","from keras.callbacks import ModelCheckpoint\n","import tensorflow as tf\n","from tensorflow.keras.metrics import BinaryAccuracy, TruePositives\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import load_model"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VDdii4o1cK61","executionInfo":{"status":"ok","timestamp":1619443270252,"user_tz":300,"elapsed":105291,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}},"outputId":"9bdcdadc-157b-4617-f347-b3b1de0b0c9d"},"source":["tf.__version__"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.3.1'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"Z79YFZ54cNGL","executionInfo":{"status":"ok","timestamp":1619443270270,"user_tz":300,"elapsed":105303,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["# See https://openslide.org/api/python/#openslide.OpenSlide.read_region\n","# Note: x,y coords are with respect to level 0.\n","# There is an example below of working with coordinates\n","# with respect to a higher zoom level.\n","\n","# Read a region from the slide\n","# Return a numpy RBG array\n","def read_slide(slide, x, y, level, width, height, as_float=False):\n","    im = slide.read_region((x,y), level, (width, height))\n","    im = im.convert('RGB') # drop the alpha channel\n","    if as_float:\n","        im = np.asarray(im, dtype=np.float32)\n","    else:\n","        im = np.asarray(im)\n","    assert im.shape == (height, width, 3)\n","    return im\n","\n","# As mentioned in class, we can improve efficiency by ignoring non-tissue areas \n","# of the slide. We'll find these by looking for all gray regions.\n","def find_tissue_pixels(image, intensity=0.8):\n","    im_gray = rgb2gray(image)\n","    assert im_gray.shape == (image.shape[0], image.shape[1])\n","    indices = np.where(im_gray <= intensity)\n","    return list(zip(indices[0], indices[1]))\n","\n","def apply_mask(im, mask, color=(255,0,0)):\n","    masked = np.copy(im)\n","    for x,y in mask: masked[x][y] = color\n","    return masked"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"txaHAWVKcVyO","executionInfo":{"status":"ok","timestamp":1619443270280,"user_tz":300,"elapsed":105303,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["# This will get all the associated zoom levels for each coordinate box\n","# each coordinate starts with the zoom level but then each level gets its own box\n","# we will only take images that are at least 50% tissue \n","# a box is determined to contain a tumor if .5% of the box is tumorous\n","def getGridImages(slide, mask, levels, img_size):\n","  slides, y_out, slide_coords = [[] for level in levels], [], []\n","\n","  coord_boxes = []\n","  max_width = slide.level_dimensions[0][0]\n","  max_height = slide.level_dimensions[0][1]\n","  for x in range(0, max_width-299, 299*(2**levels[0])):\n","    for y in range(0, max_height-299, 299*(2**(levels[0]))):\n","      coord_boxes.append([x,y])\n","  width, height, _ = img_size\n","  for i, box in enumerate(coord_boxes):\n","    x, y = box\n","    slide_img = read_slide(slide, x, y, level=levels[0], width=width, height=height)\n","    tissue_pixels = find_tissue_pixels(slide_img)\n","    percent_tissue = len(tissue_pixels) / float(slide_img.shape[0]*slide_img.shape[1])\n","    if percent_tissue < .5:\n","      continue\n","    mask_img = read_slide(mask, x, y, level=levels[0], width=width, height=height)\n","    mask_img = mask_img[:,:,0]\n","    if mask_img.sum() > 0:\n","      y_out.append(1)\n","    else:\n","      y_out.append(0)\n","    for i, level in enumerate(levels):\n","      slide_img = read_slide(slide, x, y, level=level, width=width, height=height)\n","      slide_img = slide_img.astype(float)\n","      slide_img /= 255.\n","      slides[i].append(slide_img)\n","    slide_coords.append((x, y, width, height, levels[0]))\n","\n","  return np.asarray(slides), np.asarray(y_out), slide_coords\n","      "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"IUkwFrlNcX5X","executionInfo":{"status":"ok","timestamp":1619443270281,"user_tz":300,"elapsed":105299,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["# Multichannel model, all we need to do is pick the number of levels and each\n","# level will have a InceptionV3 model generated from it\n","# We are not finetuning the inceptionV3 instead we just train a new dense layer\n","def multichannel_model(levels):\n","  model = {}\n","  for i, level in enumerate(levels):\n","    model[level] = {}\n","    model[level]['inception'] = InceptionV3(include_top=False, weights='imagenet')\n","    model[level]['inception']._name = model[level]['inception']._name + f\"_{i}\"\n","    for layer in model[level]['inception'].layers:\n","      layer.trainable = False\n","      layer._name = layer._name + f\"_{i}\"\n","    model[level]['x'] = model[level]['inception']\n","    model[level]['pool'] = GlobalAveragePooling2D()(model[level]['x'].output)\n","  merged = concatenate([model[level]['pool'] for level in model])\n","  dense = Dense(128, activation='relu')(merged)\n","  output = Dense(1, activation='sigmoid')(dense)\n","    \n","  return Model(inputs=[model[level]['x'].input for level in model], outputs=output)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5Eo6wH1dd8u"},"source":["# Create the model with the desired number of levels\n","# 3 levels is too much in memory and we get a good enough result with 2 levels\n","# We choose the lowest zoom levels that fit in memory\n","levels = [3,4]\n","model = multichannel_model(levels)\n","model.compile(optimizer='adam', loss='binary_crossentropy',\n","              metrics=BinaryAccuracy(threshold=.1))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJHwiCSFdkJo"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amhCERs4dxvB","executionInfo":{"status":"ok","timestamp":1619443280119,"user_tz":300,"elapsed":115125,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["# Get the images for training from google drive\n","np.random.seed(714)\n","path = \"drive/MyDrive/final_project_slides/\"\n","data_files = os.listdir(path)\n","# because I am training on a subset I manually chose the test set ahead of time\n","# to make sure the items will be informative to test on \n","mask_files = [file for file in data_files if '_mask.tif' in file and\n","              '031' not in file and '016' not in file and '023' not in file]\n","\n","pairs = [(path+mask[:9]+'.tif', path+mask) for mask in mask_files if mask[:9]+'.tif' in data_files]\n","np.random.shuffle(pairs)\n","train_pairs = pairs[:7]\n","val_pairs = pairs[7:10]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xYW6EzINZs1H","executionInfo":{"status":"ok","timestamp":1619444416684,"user_tz":300,"elapsed":229,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}},"outputId":"37232d5e-6a17-4e5f-a58f-588402c82cd2"},"source":["print(val_pairs)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[('drive/MyDrive/final_project_slides/tumor_005.tif', 'drive/MyDrive/final_project_slides/tumor_005_mask.tif'), ('drive/MyDrive/final_project_slides/tumor_075.tif', 'drive/MyDrive/final_project_slides/tumor_075_mask.tif'), ('drive/MyDrive/final_project_slides/tumor_059.tif', 'drive/MyDrive/final_project_slides/tumor_059_mask.tif')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EjMNbP42gsG5"},"source":["first = True\n","for slide_path, mask_path in train_pairs:\n","  print(slide_path)\n","  print(mask_path)\n","  slide= open_slide(slide_path)\n","  mask = open_slide(mask_path)\n","  if first:\n","    X_train, Y_train = getGridImages(slide, mask, levels=levels, \n","                                     img_size=(299, 299, 3))\n","    first = False\n","  else:\n","    new_X, new_Y = getGridImages(slide, mask, levels=levels, \n","                                     img_size=(299, 299, 3))\n","    X_train = np.append(X_train, new_X, axis=1)\n","    Y_train = np.append(Y_train, new_Y)\n","\n","print(X_train.shape)\n","print(len(Y_train), Y_train.sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLZBEZQjkp--","executionInfo":{"status":"aborted","timestamp":1619443283639,"user_tz":300,"elapsed":118631,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["first = True\n","for slide_path, mask_path in val_pairs:\n","  print(slide_path)\n","  print(mask_path)\n","  slide = open_slide(slide_path)\n","  mask = open_slide(mask_path)\n","  if first:\n","    X_val, Y_val = getGridImages(slide, mask, levels=levels, \n","                                     img_size=(299, 299, 3))\n","    first = False\n","  else:\n","    new_X, new_Y = getGridImages(slide, mask, levels=levels, \n","                                     img_size=(299, 299, 3))\n","    X_val = np.append(X_val, new_X, axis=1)\n","    Y_val = np.append(Y_val, new_Y)\n","\n","print(X_val.shape)\n","print(len(Y_val), Y_val.sum())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZsbhBUn7b594"},"source":["slide_path = 'tumor_091.tif' # only this file is available\n","tumor_mask_path = 'tumor_091_mask.tif' # only this file is available\n","\n","slide_url = 'https://storage.googleapis.com/applied-dl/%s' % slide_path\n","mask_url = 'https://storage.googleapis.com/applied-dl/%s' % tumor_mask_path\n","\n","# Download the whole slide image\n","if not os.path.exists(slide_path):\n","  !curl -O $slide_url\n","\n","# Download the tumor mask\n","if not os.path.exists(tumor_mask_path):\n","  !curl -O $mask_url"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xt8pK1yZdxyP","executionInfo":{"status":"aborted","timestamp":1619443283644,"user_tz":300,"elapsed":118630,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["# get variables ready to be inputted\n","train_input = [X_train[i] for i in range(len(X_train))]\n","val_input = [X_val[i] for i in range(len(X_val))]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-hJdBrljOpdK","executionInfo":{"status":"aborted","timestamp":1619443283649,"user_tz":300,"elapsed":118629,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["# free up memory so we don't crash colab\n","del X_train, X_val, new_X, new_Y\n","gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnalyjqcNWVq","executionInfo":{"status":"aborted","timestamp":1619443283650,"user_tz":300,"elapsed":118628,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["filepath = 'multichannel_inception_best_model.h5'\n","checkpoint = ModelCheckpoint(filepath, monitor='val_binary_accuracy', verbose=0, save_best_only=True, mode='max')\n","history = model.fit(train_input, Y_train, epochs=10, batch_size=16, shuffle=True,\n","          validation_data=(val_input, Y_val), callbacks=[checkpoint])\n","model = load_model('multichannel_inception_best_model.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3orZ223PJyw","executionInfo":{"status":"aborted","timestamp":1619443283651,"user_tz":300,"elapsed":118622,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["del train_input, val_input, Y_train, Y_val\n","gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yKYP24ALTljv","executionInfo":{"status":"aborted","timestamp":1619443283652,"user_tz":300,"elapsed":118620,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["def predict_boxes(boxes, slide, levels, model, width, height, img_size=(299,299,3)):\n","  multiplier = 2**levels[0]\n","  mask_box = {}\n","  for i, box in enumerate(boxes):\n","    x, y = box\n","    x = x*multiplier+5000*multiplier\n","    y = y*multiplier+16000*multiplier\n","    slide_img = read_slide(slide, x, y, level=levels[0], \n","                           width=img_size[0], height=img_size[1])\n","    \n","    tissue_pixels = find_tissue_pixels(slide_img)\n","    percent_tissue = len(tissue_pixels) / float(slide_img.shape[0]*slide_img.shape[1])\n","    if percent_tissue < .5:\n","      mask_box[box] = 0\n","      continue\n","    else:\n","      input = [[] for level in levels]\n","      for j, level in enumerate(levels):\n","        slide_img = read_slide(slide, x, y, level=level, \n","                               width=img_size[0], height=img_size[1])\n","        slide_img = slide_img.astype(float)\n","        slide_img /= 255.\n","        input[j].append(slide_img)\n","      input = np.asarray(input)\n","      input = input.reshape(2, 299, 299, 3)\n","      print(input.shape)\n","      output = model.predict([input])\n","      output = Y_pred[:, 0] > .1\n","      output.astype(int)\n","      mask_box[box] = output[0][0]\n","  \n","  return mask_box\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mpukF3SlQN9a","executionInfo":{"status":"aborted","timestamp":1619443283654,"user_tz":300,"elapsed":118613,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["def predict_mask(slide_path, mask_path, model, level, x, y, width, height, img_size=(299,299,3)):\n","  slide = open_slide(slide_path)\n","  mask = open_slide(mask_path)\n","  slide_image = read_slide(slide, \n","                          x=x*(2**level), \n","                          y=y*(2**level), \n","                          level=level, \n","                          width=width, \n","                          height=height)\n","  mask_image = read_slide(mask, \n","                        x=x*(2**level), \n","                        y=y*(2**level), \n","                        level=level, \n","                        width=width, \n","                        height=height)\n","  # boxes = []\n","  # for x_coord in range(0, width, img_size[0]):\n","  #   for y_coord in range(0, height, img_size[1]):\n","  #     boxes.append((x_coord, y_coord))\n","  # mask_box = predict_boxes(boxes, slide, levels, model, width, height)\n","  slides, y_true, y_coords = getGridImages(slide, mask, levels, (299,299,3))\n","  print(len(slides), len(y_coords))\n","  assert len(slides) == len(y_coords)\n","  input = [i for i in slides]\n","  y_pred = model.predict(input)\n","  Y_pred = Y_pred[:, 0] > .1\n","  Y_pred.astype(int)\n","  assert len(y_pred) == len(y_coords)\n","  mask = []\n","  for i, pred in enumerate(y_pred):\n","    if pred:\n","      for x in y_coords[i][0]:\n","        for y in y_coords[i][1]:\n","          mask.append((x//(2**levels[0]),y//(2**levels[0])))\n","  pred_mask = apply_mask(slide_image, mask)\n","\n","  mask_image = mask_image[:,:,0]\n","  plt.figure(figsize=(10,10), dpi=100)\n","  plt.imshow(slide_image.rotate(90))\n","  plt.title(slide_path.split(\"/\")[-1])\n","  plt.imshow(pred_mask, cmap='jet', alpha=.5)\n","  # plt.imshow(mask_image, cmap='jet', alpha=.5)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IHhalEOHiemq","executionInfo":{"status":"aborted","timestamp":1619443283654,"user_tz":300,"elapsed":118611,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qnrnH2h8fl_G","executionInfo":{"status":"aborted","timestamp":1619443283655,"user_tz":300,"elapsed":118608,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["def predict_score(slide_path, mask_path, model, levels, img_size=(299,299,3)):\n","  slide = open_slide(slide_path)\n","  mask = open_slide(mask_path)\n","  X, Y = getGridImages(slide, mask, levels=levels, \n","                                     img_size=img_size)\n","  X = [i for i in X]\n","  Y_pred = model.predict(X)\n","  Y_pred = Y_pred[:, 0] > .1\n","  Y_pred.astype(int)\n","  return classification_report(Y, Y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hfoJF_PC54Ix","executionInfo":{"status":"aborted","timestamp":1619443283657,"user_tz":300,"elapsed":118598,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["# chosen because there is a large amount of tumor but it is spread out\n","slide_path = 'drive/MyDrive/final_project_slides/tumor_031.tif'\n","mask_path = 'drive/MyDrive/final_project_slides/tumor_031_mask.tif'\n","predict_mask(slide_path, mask_path, model, levels[0], 5000, 16000, 6000, 6000)\n","print(predict_score(slide_path, mask_path, model, levels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rpaxTdi54y0","executionInfo":{"status":"aborted","timestamp":1619443283668,"user_tz":300,"elapsed":118604,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["# chosen because there is a large amount of tumor concentrated\n","slide_path = 'drive/MyDrive/final_project_slides/tumor_016.tif'\n","mask_path = 'drive/MyDrive/final_project_slides/tumor_016_mask.tif'\n","predict_mask(slide_path, mask_path, model, 7)\n","print(predict_score(slide_path, mask_path, model, levels))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A0Vtqqci57DM","executionInfo":{"status":"aborted","timestamp":1619443283668,"user_tz":300,"elapsed":118597,"user":{"displayName":"Jack Atkins","photoUrl":"","userId":"17315053861884105944"}}},"source":["# chosen because there is almost no tumor to be found\n","slide_path = 'drive/MyDrive/final_project_slides/tumor_023.tif'\n","mask_path = 'drive/MyDrive/final_project_slides/tumor_023_mask.tif'\n","predict_mask(slide_path, mask_path, model, 6)\n","print(predict_score(slide_path, mask_path, model, levels))"],"execution_count":null,"outputs":[]}]}